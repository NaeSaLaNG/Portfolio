{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67f165c4",
   "metadata": {},
   "source": [
    "# Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bb3ee95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import textstat\n",
    "import optuna\n",
    "import pysrt\n",
    "import nltk\n",
    "import ssl\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5608563c",
   "metadata": {},
   "source": [
    "## Запустить при первом запуске."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48a6eb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssl._create_default_https_context = ssl._create_unverified_context\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3e823f",
   "metadata": {},
   "source": [
    "# Открытие данных "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f32193b",
   "metadata": {},
   "source": [
    "## Открытие excel и обработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d78e4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_Cloverfield_lane(2016)</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_things_I_hate_about_you(1999)</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A_knights_tale(2001)</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A_star_is_born(2018)</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aladdin(1992)</td>\n",
       "      <td>A2/A2+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Movie   Level\n",
       "0         10_Cloverfield_lane(2016)      B1\n",
       "1  10_things_I_hate_about_you(1999)      B1\n",
       "2              A_knights_tale(2001)      B2\n",
       "3              A_star_is_born(2018)      B2\n",
       "4                     Aladdin(1992)  A2/A2+"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('english_level/english_scores/movies_labels.xlsx').drop('id', axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be47485e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B2            101\n",
       "B1             55\n",
       "C1             40\n",
       "A2/A2+         26\n",
       "B1, B2          8\n",
       "A2              6\n",
       "A2/A2+, B1      5\n",
       "Name: Level, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Level\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89aa9a91",
   "metadata": {},
   "source": [
    "Заменим промежуточные уровни на определенные, чтобы в итоге получить более равномерное распределение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcfcfa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictinory = {\"A2/A2+\": \"A2\", \"B1, B2\": \"B1\", \"A2/A2+, B1\": \"B1\"}\n",
    "df[\"Level\"] = df[\"Level\"].replace(dictinory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a01f18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Inside_out(2015)</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Powder(1995)</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The_terminal(2004)</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Movie Level\n",
       "44    Inside_out(2015)    B1\n",
       "68        Powder(1995)    B1\n",
       "99  The_terminal(2004)    B1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd04203",
   "metadata": {},
   "source": [
    "Удаляем дубликаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86bbaac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebef23ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Movie    0\n",
       "Level    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693e1ebb",
   "metadata": {},
   "source": [
    "## Открытие субтитров и обработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a186a8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML = r'<.*?>'\n",
    "TAG = r'{.*?}'\n",
    "COMMENTS = r'[\\(\\[][A-Z ]+[\\)\\]]'\n",
    "SPACES = r'([ ])\\1+'\n",
    "DOTS = r'[\\.]+'\n",
    "\n",
    "def clean_subs(subs):\n",
    "    txt = re.sub(HTML, ' ', subs) # html тэги меняем на пробел\n",
    "    txt = re.sub(TAG, ' ', txt) # тэги меняем на пробел\n",
    "    txt = re.sub(COMMENTS, ' ', txt) # комменты меняем на пробел\n",
    "    txt = re.sub(SPACES, r'\\1', txt) # повторяющиеся пробелы меняем на один пробел\n",
    "    txt = re.sub(DOTS, r'.', txt) # многоточие меняем на точку\n",
    "    txt = txt.encode('ascii', 'ignore').decode() # удаляем все что не ascii символы\n",
    "    txt = \".\".join(txt.lower().split('.')[1:-1]) # удаляем первый и последний субтитр (обычно это реклама)\n",
    "    txt = re.sub(r\"\\n\", \"\", txt)\n",
    "\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32fbfcde",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>level_filepath</th>\n",
       "      <th>sub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aladdin(1992)</td>\n",
       "      <td>Subtitles</td>\n",
       "      <td>please, please, come closer.too close. a littl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The_Intern(2015)</td>\n",
       "      <td>Subtitles</td>\n",
       "      <td>work and love.that's all there is.\"well, i'm r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The_Fundamentals_of_Caring(2016)</td>\n",
       "      <td>Subtitles</td>\n",
       "      <td>it is also about understandinghow to navigatea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Her(2013)</td>\n",
       "      <td>Subtitles</td>\n",
       "      <td>opensubtitles.org todaywww.titlovi.com\"to my c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matilda(1996)</td>\n",
       "      <td>Subtitles</td>\n",
       "      <td>some will grow to be butchers orbakers or ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Movie level_filepath  \\\n",
       "0                     Aladdin(1992)      Subtitles   \n",
       "1                  The_Intern(2015)      Subtitles   \n",
       "2  The_Fundamentals_of_Caring(2016)      Subtitles   \n",
       "3                         Her(2013)      Subtitles   \n",
       "4                     Matilda(1996)      Subtitles   \n",
       "\n",
       "                                                 sub  \n",
       "0  please, please, come closer.too close. a littl...  \n",
       "1  work and love.that's all there is.\"well, i'm r...  \n",
       "2  it is also about understandinghow to navigatea...  \n",
       "3  opensubtitles.org todaywww.titlovi.com\"to my c...  \n",
       "4    some will grow to be butchers orbakers or ca...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs = pd.DataFrame({\"Movie\": [], \"level_filepath\":[], \"sub\": []})\n",
    "root_directory = os.path.abspath(\"\") + '/english_level/english_scores/Subtitles_all/'\n",
    "extension = '.srt'\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(root_directory):\n",
    "    for file_name in files:\n",
    "        if file_name.endswith(extension):\n",
    "            file_path = os.path.join(root, file_name)\n",
    "            try: sub = clean_subs(pysrt.open(file_path).text)\n",
    "            except:\n",
    "                try: sub = clean_subs(pysrt.open(file_path, encoding='latin-1').text)\n",
    "                except: sub = clean_subs(pysrt.open(file_path, encoding='cp1252').text)\n",
    "            parts = file_path.split(\"/\")\n",
    "            subs = pd.concat([pd.Series({\"Movie\": \".\".join(parts[-1].split(\".\")[:-1]), \n",
    "                                       \"level_filepath\":parts[-2], \n",
    "                                       \"sub\":sub}),\n",
    "                            subs], ignore_index=True, axis = 1)\n",
    "subs = subs.T.dropna()\n",
    "subs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1a9a2b",
   "metadata": {},
   "source": [
    "## Соединение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5bcb036",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.merge(subs, on = 'Movie', how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c65790df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Movie              0\n",
       "Level             48\n",
       "level_filepath     7\n",
       "sub                7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f96d110",
   "metadata": {},
   "source": [
    "Обобщим уровни в переменные \"Level\" и \"level_filepath\". Затем заменить пропущенные значения в переменной \"Level\" имеющимися данными из \"level_filepath\". \n",
    "\n",
    "Удалить фильмы, у которых уровень указан как \"Subtitles\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d565853",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Level'] = df['Level'].fillna(df['level_filepath'])\n",
    "df = df[df['Level'] != \"Subtitles\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1e3c3e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Movie             0\n",
       "Level             0\n",
       "level_filepath    7\n",
       "sub               7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75c9e7a",
   "metadata": {},
   "source": [
    "Теперь можно убрать level_filepath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b9aebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('level_filepath', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c022998",
   "metadata": {},
   "source": [
    "В данных присутствует 7 пропусков, которые требуется заполнить. Поскольку имеется очень мало данных, оценка уровня фильмов, отсутствующих в этих данных, требует глубокого анализа произведения, что усложняет их добавление из стороних источников."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2bb1325",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_directory = os.path.abspath(\"\") + '/english_level/other_movie'\n",
    "\n",
    "for root, dirs, files in os.walk(root_directory):\n",
    "    for file_name in files:\n",
    "        if file_name.endswith(extension):\n",
    "            file_path = os.path.join(root, file_name)\n",
    "            try: sub = clean_subs(pysrt.open(file_path).text)\n",
    "            except:\n",
    "                try: sub = clean_subs(pysrt.open(file_path, encoding='latin-1').text)\n",
    "                except: sub = clean_subs(pysrt.open(file_path, encoding='cp1252').text)\n",
    "            parts = file_path.split(\"/\")\n",
    "            movie_name = \".\".join(parts[-1].split(\".\")[:-1])\n",
    "            df.loc[df[\"Movie\"] == movie_name, 'sub'] = sub\n",
    "            if movie_name == \"Thor love and thunder\":\n",
    "                df.loc[df[\"Movie\"] == \"Thor: love and thunder\", 'sub'] = sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "834b058e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>Level</th>\n",
       "      <th>sub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_Cloverfield_lane(2016)</td>\n",
       "      <td>B1</td>\n",
       "      <td>enjoy the flick     ben on phone: michelle, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_things_I_hate_about_you(1999)</td>\n",
       "      <td>B1</td>\n",
       "      <td>so, cameron. here you go.nine schools in 1 0 y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A_knights_tale(2001)</td>\n",
       "      <td>B2</td>\n",
       "      <td>two minutes or forfeit.lend us those.right. le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A_star_is_born(2018)</td>\n",
       "      <td>B2</td>\n",
       "      <td>black eyes open wideit's time to testify   t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aladdin(1992)</td>\n",
       "      <td>A2</td>\n",
       "      <td>please, please, come closer.too close. a littl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>Crown, The S01E03 - Windsor.en</td>\n",
       "      <td>B2</td>\n",
       "      <td>-are you hearing me? -hear you clearly. stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>Crown, The S01E05 - Smoke and Mirrors.en</td>\n",
       "      <td>B2</td>\n",
       "      <td>ah, there you are. come in.i'm practicing for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>Crown, The S01E04 - Act of God.en.SDH</td>\n",
       "      <td>B2</td>\n",
       "      <td>-[philip] fuel on.chocks are in position. swit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Virgin.River.S01E07.INTERNAL.720p.WEB.x264-STRiFE</td>\n",
       "      <td>B2</td>\n",
       "      <td>you were right.it's time for me to go home.oh,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>Crown, The S01E01 - Wolferton Splash.en</td>\n",
       "      <td>B2</td>\n",
       "      <td>-here, sir..and all foreign titles.and, from h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>278 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Movie Level  \\\n",
       "0                            10_Cloverfield_lane(2016)    B1   \n",
       "1                     10_things_I_hate_about_you(1999)    B1   \n",
       "2                                 A_knights_tale(2001)    B2   \n",
       "3                                 A_star_is_born(2018)    B2   \n",
       "4                                        Aladdin(1992)    A2   \n",
       "..                                                 ...   ...   \n",
       "281                     Crown, The S01E03 - Windsor.en    B2   \n",
       "282           Crown, The S01E05 - Smoke and Mirrors.en    B2   \n",
       "283              Crown, The S01E04 - Act of God.en.SDH    B2   \n",
       "284  Virgin.River.S01E07.INTERNAL.720p.WEB.x264-STRiFE    B2   \n",
       "285            Crown, The S01E01 - Wolferton Splash.en    B2   \n",
       "\n",
       "                                                   sub  \n",
       "0     enjoy the flick     ben on phone: michelle, p...  \n",
       "1    so, cameron. here you go.nine schools in 1 0 y...  \n",
       "2    two minutes or forfeit.lend us those.right. le...  \n",
       "3      black eyes open wideit's time to testify   t...  \n",
       "4    please, please, come closer.too close. a littl...  \n",
       "..                                                 ...  \n",
       "281    -are you hearing me? -hear you clearly. stan...  \n",
       "282  ah, there you are. come in.i'm practicing for ...  \n",
       "283  -[philip] fuel on.chocks are in position. swit...  \n",
       "284  you were right.it's time for me to go home.oh,...  \n",
       "285  -here, sir..and all foreign titles.and, from h...  \n",
       "\n",
       "[278 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8057b00a",
   "metadata": {},
   "source": [
    "# Добавление новых признаков и дополнительная обработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea020560",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = set(stopwords.words('english') + ['uh', 'oh', 'hmm', 'huh', 'ha', 'oooh'])\n",
    "STEMMER = WordNetLemmatizer()\n",
    "LETTERS = r'[^a-zA-Z\\'.,!? ]'\n",
    "\n",
    "\n",
    "def text_stats(row):\n",
    "    row['smog_index'] = textstat.smog_index(row['sub'])\n",
    "    row['coleman_liau_index'] = textstat.coleman_liau_index(row['sub'])\n",
    "    row[\"dale_chall_readability_score\"] = textstat.dale_chall_readability_score(row['sub'])\n",
    "    row[\"gunning_fog\"] = textstat.gunning_fog(row['sub'])\n",
    "    \n",
    "    txt = row['sub']\n",
    "    txt = re.sub(LETTERS, ' ', txt) # все что не буквы меняем на пробел\n",
    "    txt = re.sub(r\"[^\\w\\s]\", \"\", txt)\n",
    "    txt = word_tokenize(txt)\n",
    "    txt = \" \".join([STEMMER.lemmatize(word) for word in txt if word.lower() not in STOP_WORDS])\n",
    "    \n",
    "    row['sub'] = txt\n",
    "    \n",
    "    return row\n",
    "\n",
    "df = df.apply(text_stats, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "551694dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = {\"B2\": 3,\n",
    "        \"B1\": 2,\n",
    "        \"C1\": 4,\n",
    "        \"A2\": 1}\n",
    "\n",
    "df['Level'] = df['Level'].map(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f8a255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.1)\n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a743fc",
   "metadata": {},
   "source": [
    "# Подбор гипер параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45753b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective(trial: optuna.trial.Trial):\n",
    "#     train_local = train.copy\n",
    "#     params = {\n",
    "#         'iterations': trial.suggest_int(\"iterations\", 100, 1000),\n",
    "#         'learning_rate': trial.suggest_float(\"learning_rate\", 1e-2, 1e-1, log=True),\n",
    "#         'depth': trial.suggest_int(\"depth\", 4, 10),\n",
    "#         'l2_leaf_reg': trial.suggest_float(\"l2_leaf_reg\", 1e-8, 100.0, log=True),\n",
    "#         'random_strength': trial.suggest_float(\"random_strength\", 1e-8, 10.0, log=True),\n",
    "#         'od_type': trial.suggest_categorical(\"od_type\", [\"IncToDec\", \"Iter\"]),\n",
    "#         'od_wait': trial.suggest_int(\"od_wait\", 10, 50),\n",
    "#         'random_seed': 1234,\n",
    "#         'eval_metric': \"MultiClass\",\n",
    "#         'verbose': False,\n",
    "#         \"loss_function\":'MultiClass',\n",
    "#         \"auto_class_weights\": 'Balanced'}\n",
    "\n",
    "#     vectorizer_param = {\n",
    "#         \"max_features\":trial.suggest_int(\"max_features\", 100, 2000),\n",
    "#         \"min_df\":trial.suggest_int(\"min_df\", 0, 100),\n",
    "#         \"max_df\":trial.suggest_float(\"max_df\", 0.5, 1, log=True)}\n",
    "    \n",
    "#     Vectorizer = TfidfVectorizer(**vectorizer_param, stop_words=None)\n",
    "#     train_local = train.merge(pd.DataFrame(Vectorizer.fit_transform(train['sub']).toarray()), \n",
    "#                         left_index=True, \n",
    "#                         right_index=True)\n",
    "#     train_local = train_local.drop(['sub', 'Movie'], axis = 1)\n",
    "    \n",
    "#     features = train_local.drop(\"Level\", axis = 1)\n",
    "#     target = train_local['Level']\n",
    "    \n",
    "#     results = []\n",
    "#     random_seed = np.random.RandomState(1234)\n",
    "\n",
    "#     kf = KFold(n_splits=3, shuffle=True, random_state=1234)\n",
    "#     for train_index, test_index in kf.split(features):\n",
    "\n",
    "#         features_train, features_test = features.iloc[train_index], features.iloc[test_index]\n",
    "#         target_train, target_test = target.iloc[train_index], target.iloc[test_index]\n",
    "\n",
    "#         features_train, features_valid, target_train, target_valid = train_test_split(features_train,\n",
    "#                                                                                       target_train,\n",
    "#                                                                                       test_size=0.1,\n",
    "#                                                                                       random_state=random_seed)\n",
    "#         model = CatBoostClassifier(**params)\n",
    "#         model.fit(features_train, target_train,\n",
    "#                   use_best_model=True,\n",
    "#                   eval_set=(features_valid,\n",
    "#                             target_valid),\n",
    "#                   early_stopping_rounds=50)\n",
    "        \n",
    "#         prediction = model.predict(features_test)\n",
    "#         results.append(balanced_accuracy_score(target_test, prediction))\n",
    "        \n",
    "#     print(params)\n",
    "#     print()\n",
    "#     print(vectorizer_param)\n",
    "#     return np.mean(results)\n",
    "\n",
    "\n",
    "# studies = optuna.create_study(direction='maximize', study_name=\"CatBoost\")\n",
    "# studies.optimize(objective, n_trials=1000)\n",
    "# best_catboost_params = studies.best_params | {'random_seed': 1234, 'verbose': False,\n",
    "#                                               'eval_metric': \"BalancedAccuracy\", }\n",
    "# studies.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaa7419",
   "metadata": {},
   "source": [
    "Для простоты пропустим подбор гиперпараметров.\n",
    "\n",
    "\n",
    "Полученные в ходе подбора гипер параметры:\n",
    "\n",
    "{'iterations': 719, 'learning_rate': 0.015748110341147425, 'depth': 5, 'l2_leaf_reg': 18.974532325902207, 'random_strength': 2.9674758606838096e-07, 'od_type': 'IncToDec', 'od_wait': 35, 'random_seed': 1234, 'eval_metric': 'MultiClass', 'verbose': False, 'loss_function': 'MultiClass', 'auto_class_weights': 'Balanced'}\n",
    "\n",
    "{'max_features': 1921, 'min_df': 83, 'max_df': 0.9191182527705366}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a801636",
   "metadata": {},
   "source": [
    "# Создание финальной модели и выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5caa1e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_boost_param = {'iterations': 719, 'learning_rate': 0.015748110341147425, \n",
    "                   'depth': 5, 'l2_leaf_reg': 18.974532325902207, \n",
    "                   'random_strength': 2.9674758606838096e-07, 'od_type': 'IncToDec', \n",
    "                   'od_wait': 35, 'random_seed': 1234, 'eval_metric': 'MultiClass', \n",
    "                   'verbose': False, 'loss_function': 'MultiClass', \n",
    "                   'auto_class_weights': 'Balanced'}\n",
    "\n",
    "vectorizer_param = {'max_features': 3000, 'min_df': 83, 'max_df': 0.9191182527705366}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e115aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_boost = CatBoostClassifier(**cat_boost_param)\n",
    "vectorizer = TfidfVectorizer(**vectorizer_param, stop_words=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43e51638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_and_y(dataframe):\n",
    "    \n",
    "    dataframe = dataframe.drop(['sub', 'Movie'], axis = 1)\n",
    "    \n",
    "    X = dataframe.drop(\"Level\", axis = 1)\n",
    "    y = dataframe['Level']\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "vectorizer.fit(train['sub'])\n",
    "train = train.merge(pd.DataFrame(vectorizer.transform(train['sub']).toarray()), \n",
    "                left_index=True, \n",
    "                right_index=True)\n",
    "test = test.merge(pd.DataFrame(vectorizer.transform(test['sub']).toarray()), \n",
    "                left_index=True, \n",
    "                right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06b4ca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, target_train = get_X_and_y(train)\n",
    "features_test, target_test = get_X_and_y(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1f0783d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x291440f40>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train, features_valid, target_train, target_valid = train_test_split(features_train,\n",
    "                                                                              target_train,\n",
    "                                                                              test_size=0.1,\n",
    "                                                                              random_state=1234)\n",
    "cat_boost.fit(features_train, target_train,\n",
    "             use_best_model=True,\n",
    "                  eval_set=(features_valid,\n",
    "                            target_valid),\n",
    "                  early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3395ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71875"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Качетсво модели\", balanced_accuracy_score(target_test, cat_boost.predict(features_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d751c9f",
   "metadata": {},
   "source": [
    "**Выводы**\n",
    "\n",
    "В ходе нашей работы мы провели исследование английских фильмов, разделенных на различные уровни сложности. Одной из важных задач было собрать недостающие субтитры и подготовить их для использования в моделях машинного обучения.\n",
    "\n",
    "В процессе анализа предоставленных фильмов мы обнаружили существенный дисбаланс в уровнях сложности. Особенно заметно было недостаточное количество фильмов с категорией A2, а также наличие промежуточных категорий. Учитывая недостаток данных, мы приняли решение исключить промежуточные категории.\n",
    "\n",
    "В результате наших усилий нам удалось создать модель с balanced accuracy, достигающей уровня 0.7187. Однако, для дальнейшего улучшения качества работы, мы настоятельно рекомендуем предоставить большее количество размеченных фильмов. Это позволит улучшить точность и обобщающую способность модели, обеспечивая более надежные результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c5d0e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
